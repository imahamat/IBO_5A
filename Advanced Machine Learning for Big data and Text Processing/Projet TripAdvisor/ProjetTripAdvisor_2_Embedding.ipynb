{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetTripAdvisor_2_Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RU96zjHKc0",
        "colab_type": "text"
      },
      "source": [
        "# Projet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUy0-jxDsmN",
        "colab_type": "code",
        "outputId": "9c6677ef-446f-4bde-82a8-9f3b075aa837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMxmpyJDyPm",
        "colab_type": "code",
        "outputId": "161de582-ceed-4487-8731-2b8e2b07b04f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.preprocessing.text\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import multilabel_confusion_matrix as mcm\n",
        "import tensorflow_hub as hub\n",
        "tf.keras.backend.clear_session()\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "pd.options.display.max_colwidth = 1000"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMZ5-6pjDz9J",
        "colab_type": "code",
        "outputId": "4531bca2-7098-4da8-8914-e7c617068507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4aDDiWiD5ny",
        "colab_type": "code",
        "outputId": "ae6755f7-d90f-4671-91f9-da9d0a5eaec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bsea9HMHR5X",
        "colab_type": "text"
      },
      "source": [
        "# Read CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWC424JhD-yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Total_data_for_tokenizer=pd.read_csv('/content/gdrive/My Drive/Data/Total_data_for_tokenizer.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QenSQ2ccHV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_TripAdvisor=pd.read_csv('/content/gdrive/My Drive/Data/training_set_TripAdvisor.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LE3idEjcHTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_TripAdvisor=pd.read_csv('/content/gdrive/My Drive/Data/test_set_TripAdvisor.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9IEqjrDcHJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_IMDB=pd.read_csv('/content/gdrive/My Drive/Data/training_set_IMDB.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAfJyS7ZcG83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_IMDB=pd.read_csv('/content/gdrive/My Drive/Data/test_set_IMDB.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCLtDdIREMEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_tfds_IMDB=pd.read_csv('/content/gdrive/My Drive/Data/data_tfds_IMDB.csv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVp-2faLENYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#all_data_TripAdvisor=pd.read_csv('/content/gdrive/My Drive/Data/all_data_TripAdvisor.csv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAfKBU-zEOyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del Total_data_for_tokenizer['Unnamed: 0']\n",
        "del training_set_TripAdvisor['Unnamed: 0']\n",
        "del test_set_TripAdvisor['Unnamed: 0']\n",
        "del training_set_IMDB['Unnamed: 0']\n",
        "del test_set_IMDB['Unnamed: 0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiq0-ziWHUtS",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOz-69QqEQhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(dataframe):\n",
        "  msk = np.random.rand(len(dataframe)) < 0.8\n",
        "\n",
        "  train = dataframe[msk]\n",
        "\n",
        "  test = dataframe[~msk]\n",
        "  #print(train_file_path.head)\n",
        "  all_data = np.array(dataframe.values.tolist())\n",
        "  training_set = np.array(train.values.tolist())\n",
        "  test_set=np.array(test.values.tolist())\n",
        "  print(\"Dataset Length: \",len(training_set)+ len(test_set))\n",
        "  return all_data, training_set, test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xmJa7elEaf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(dataset):\n",
        "  # create the tokenizer\n",
        "  #max_features = 6000\n",
        "  #tokenizer = Tokenizer(num_words=max_features , filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='UNK')\n",
        "  \n",
        "  tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='UNK')\n",
        "  # fit the tokenizer on the documents\n",
        "  tokenizer.fit_on_texts(dataset[:,1])\n",
        "  # summarize what was learned\n",
        "  print(\"Word counter: \",tokenizer.word_counts)\n",
        "  print(\"Number of sentences: \",tokenizer.document_count)\n",
        "  print(\"Word Index: \", tokenizer.word_index)\n",
        "  print(\"Word Docs: \",tokenizer.word_docs)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzgs633HEcT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocab_size(tokenizer):\n",
        "  voca_size=len(tokenizer.word_counts)+2   # 1 ?\n",
        "  return voca_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeuYm_kfEeHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxlen(data):\n",
        "  return max([len(x) for x in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUuLrAo6Fvzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Total_data_for_tokenizer_np = np.array(Total_data_for_tokenizer.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFBvle7NFyRr",
        "colab_type": "code",
        "outputId": "523076b2-bda2-4cf7-f1f5-9e1a47621bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "tokenizer=create_tokenizer(Total_data_for_tokenizer_np)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvPDBdUrFCkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_sentences(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      input_sequences.append(token_list)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIquk1ad4b_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_IMDB_np = np.array(training_set_IMDB.values.tolist())\n",
        "test_set_IMDB_np = np.array(test_set_IMDB.values.tolist())\n",
        "training_set_TripAdvisor_np = np.array(training_set_TripAdvisor.values.tolist())\n",
        "test_set_TripAdvisor_np = np.array(test_set_TripAdvisor.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2cPPJGIRFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_training_set_IMDB = tokenize_sentences(training_set_IMDB_np)\n",
        "input_test_set_IMDB = tokenize_sentences(test_set_IMDB_np)\n",
        "input_training_set_TripAdvisor = tokenize_sentences(training_set_TripAdvisor_np)\n",
        "input_test_set_TripAdvisor = tokenize_sentences(test_set_TripAdvisor_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47Oa5LZHDyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences = np.array(pad_sequences(input_sequences,   \n",
        "                            maxlen=max_sequence_len, padding='pre'))\n",
        "  return input_padded_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVNusWKhH1n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences_post(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences = np.array(pad_sequences(input_sequences,   \n",
        "                            maxlen=max_sequence_len, padding='post'))\n",
        "  return input_padded_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZoxfGSD7Bz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxlen(data1, data2 , data3 , data4):\n",
        "  max_len_data1 = max([len(x) for x in data1])\n",
        "  max_len_data2 = max([len(x) for x in data2])\n",
        "  max_len_data3 = max([len(x) for x in data3])\n",
        "  max_len_data4 = max([len(x) for x in data4])\n",
        "  return max(max_len_data1, max_len_data2 , max_len_data3 , max_len_data4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSPMGUSIZdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = maxlen(input_training_set_IMDB, input_test_set_IMDB, input_training_set_TripAdvisor, input_test_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH2-LjrHLseD",
        "colab_type": "text"
      },
      "source": [
        "#Embeddings pretraining (Next Word Prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM4rkTCpIQ3s",
        "colab_type": "code",
        "outputId": "91684793-02cd-4e1a-9ac3-bae37f2d1f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''def split_sentences_forward(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(line)):\n",
        "        if i < 99 :\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "        else :\n",
        "          n_gram_sequence = token_list[i-99:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def split_sentences_forward(input_set):\\n  input_sequences = []\\n  for line in input_set[:,1]:\\n      token_list = tokenizer.texts_to_sequences([line])[0]\\n      for i in range(1, len(line)):\\n        if i < 99 :\\n          n_gram_sequence = token_list[:i+1]\\n        else :\\n          n_gram_sequence = token_list[i-99:i+1]\\n        input_sequences.append(n_gram_sequence)\\n  return input_sequences'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO09_K6rhKmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentences_forward(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set:\n",
        "      for i in range(1, len(line)):\n",
        "        if i < 99 :\n",
        "          n_gram_sequence = line[:i+1]\n",
        "        else :\n",
        "          n_gram_sequence = line[i-99:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECyx4rQDL7yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentences_Backward(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "        if i < 99 :\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "        else :\n",
        "          n_gram_sequence = token_list[i-99:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hhoLTQL7d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_embaddings(input_sequences):\n",
        "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "  #label = tf.keras.utils.to_categorical(label, num_classes=voc_size)\n",
        "  return predictors, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaD5DgDdL7X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_preprocessed_dataset(predictors, labels):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((predictors, labels))\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j957uTnYL7SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_k_categorical_accuracy1(y_true, y_pred, k=10):\n",
        "    return K.mean(K.in_top_k(K.cast(y_pred,dtype='float32'),K.argmax(y_true, axis=-1), k), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z77__hlvmSAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_1=split_sentences_forward(input_training_set_IMDB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uo-sgQVL7ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_2=split_sentences_forward(input_training_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl1SrkOlL7EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test_WE_1=split_sentences_forward(input_test_set_IMDB[5000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Kq5ZeXNxPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test_WE_2=split_sentences_forward(input_test_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToeSIb11N_hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_sequences_1 = pad_sentences(input_train_WE_1, 100)\n",
        "input_train_WE_sequences_2 = pad_sentences(input_train_WE_2, 100)\n",
        "input_test_WE_sequences_1 = pad_sentences(input_test_WE_1, 100)\n",
        "input_test_WE_sequences_2 = pad_sentences(input_test_WE_2, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dizSto_OA7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors_WE, training_label_WE=create_dataset_slices_embaddings(input_train_WE_sequences_1)\n",
        "test_predictors_WE, test_label_WE= create_dataset_slices_embaddings(input_test_WE_sequences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzHWW7OTOAz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors_WE_2, training_label_WE_2=create_dataset_slices_embaddings(input_train_WE_sequences_2)\n",
        "test_predictors_WE_2, test_label_WE_2= create_dataset_slices_embaddings(input_test_WE_sequences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okRfBEGkOArD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_size = vocab_size(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM_W-v3Y8U_F",
        "colab_type": "code",
        "outputId": "109378bf-5f8f-4bcf-c627-7f1eecdd133a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "voc_size"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7TmdMeVj70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 6000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42UyQQ-OAkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EmbeddingLayer = tf.keras.layers.Embedding(max_features, 64)\n",
        "EmbeddingLayer = tf.keras.layers.Embedding(voc_size, 64)\n",
        "LstmLayer = tf.keras.layers.LSTM(150)\n",
        "DenseLayerEmbedding = tf.keras.layers.Dense(64, activation='relu')\n",
        "DropLayerEmbedding = tf.keras.layers.Dropout(0.1)\n",
        "DenseLayerOutputEmbedding = tf.keras.layers.Dense(voc_size, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le1jonZJOAdM",
        "colab_type": "code",
        "outputId": "b993ea54-286c-4e20-8594-6a1694098e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(EmbeddingLayer)\n",
        "model.add(LstmLayer)\n",
        "model.add(DenseLayerEmbedding)\n",
        "model.add(DropLayerEmbedding)\n",
        "model.add(DenseLayerOutputEmbedding)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          5120512   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 150)               129000    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                9664      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 80008)             5200520   \n",
            "=================================================================\n",
            "Total params: 10,459,696\n",
            "Trainable params: 10,459,696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letBgMTdOAVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3zGjAZyPTNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_Embadding/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKQJD5J3PURJ",
        "colab_type": "code",
        "outputId": "e1160db3-1e8a-42d2-fe55-ff050d6a89ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "history = model.fit(training_predictors_WE, \n",
        "                    training_label_WE,\n",
        "                    epochs=3,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_WE, test_label_WE),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3616784 samples, validate on 2831359 samples\n",
            "Epoch 1/3\n",
            "3616700/3616784 [============================>.] - ETA: 0s - loss: 7.6890 - accuracy: 0.0601\n",
            "Epoch 00001: saving model to training_Embadding/cp-0001.ckpt\n",
            "3616784/3616784 [==============================] - 3023s 836us/sample - loss: 7.6890 - accuracy: 0.0601 - val_loss: 7.5776 - val_accuracy: 0.0713\n",
            "Epoch 2/3\n",
            "1828800/3616784 [==============>...............] - ETA: 20:11 - loss: 7.4246 - accuracy: 0.0731Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLrNPWztPYRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "4ac471ae-7735-4f87-b17d-d5d76b1c0485"
      },
      "source": [
        "history = model.fit(training_predictors_WE_2, \n",
        "                    training_label_WE_2,\n",
        "                    epochs=5,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_WE_2, test_label_WE_2),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 947983 samples, validate on 237895 samples\n",
            "Epoch 1/5\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 5.7881 - accuracy: 0.1432\n",
            "Epoch 00001: saving model to training_Embadding/cp-0001.ckpt\n",
            "947983/947983 [==============================] - 710s 749us/sample - loss: 5.7880 - accuracy: 0.1432 - val_loss: 5.1368 - val_accuracy: 0.1876\n",
            "Epoch 2/5\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 5.0393 - accuracy: 0.1938\n",
            "Epoch 00002: saving model to training_Embadding/cp-0002.ckpt\n",
            "947983/947983 [==============================] - 712s 751us/sample - loss: 5.0393 - accuracy: 0.1938 - val_loss: 4.8432 - val_accuracy: 0.2122\n",
            "Epoch 3/5\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 4.7762 - accuracy: 0.2128\n",
            "Epoch 00003: saving model to training_Embadding/cp-0003.ckpt\n",
            "947983/947983 [==============================] - 714s 753us/sample - loss: 4.7762 - accuracy: 0.2128 - val_loss: 4.7101 - val_accuracy: 0.2229\n",
            "Epoch 4/5\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 4.6169 - accuracy: 0.2244\n",
            "Epoch 00004: saving model to training_Embadding/cp-0004.ckpt\n",
            "947983/947983 [==============================] - 715s 755us/sample - loss: 4.6168 - accuracy: 0.2244 - val_loss: 4.6299 - val_accuracy: 0.2311\n",
            "Epoch 5/5\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 4.5067 - accuracy: 0.2321\n",
            "Epoch 00005: saving model to training_Embadding/cp-0005.ckpt\n",
            "947983/947983 [==============================] - 711s 750us/sample - loss: 4.5067 - accuracy: 0.2321 - val_loss: 4.5920 - val_accuracy: 0.2347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbTOCWHoBzG",
        "colab_type": "text"
      },
      "source": [
        "#BI-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z4DMzBePkFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDb5mtweJn4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_CL_sequences_1 = pad_sentences_post(input_training_set_IMDB, max_len)\n",
        "input_train_CL_sequences_2 = pad_sentences_post(input_training_set_TripAdvisor, max_len)\n",
        "input_test_CL_sequences_1 = pad_sentences_post(input_test_set_IMDB, max_len)\n",
        "input_test_CL_sequences_2 = pad_sentences_post(input_test_set_TripAdvisor, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kIIowNgA8gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_sentence_classification(input_sequences, targets):\n",
        "  predictors= tf.constant(input_sequences)\n",
        "  targets=targets.astype(int)\n",
        "  nb_classes = 5\n",
        "  targets = targets.reshape(-1)\n",
        "  one_hot_targets = np.eye(nb_classes)[targets-1]\n",
        "  return predictors, one_hot_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osgFg5rijCSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors, training_label=create_dataset_slices_sentence_classification(input_train_CL_sequences_2,training_set_TripAdvisor_np[:,0])\n",
        "test_predictors, test_label=create_dataset_slices_sentence_classification(input_test_CL_sequences_2,test_set_TripAdvisor_np[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phDBKoF0q-yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_sentence_classification_bina(input_sequences, targets):\n",
        "  predictors= tf.constant(input_sequences)\n",
        "  targets=targets.astype(int)\n",
        "  nb_classes = 2\n",
        "  targets = targets.reshape(-1)\n",
        "  one_hot_targets = np.eye(nb_classes)[targets-1]\n",
        "  return predictors, one_hot_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L80paZ2urDvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors_tfds, training_label_tfds=create_dataset_slices_sentence_classification_bina(input_train_CL_sequences_1,training_set_IMDB_np[:,0])\n",
        "test_predictors_tfds, test_label_tfds=create_dataset_slices_sentence_classification_bina(input_test_CL_sequences_1,test_set_IMDB_np[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmjRPMxwF-YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BidirectionalLayer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences = True))\n",
        "GlobalMaxPool1DLayer = tf.keras.layers.GlobalMaxPool1D()\n",
        "DenseLayer = tf.keras.layers.Dense(20, activation='relu')\n",
        "DropLayer = tf.keras.layers.Dropout(0.05)\n",
        "DenseLayerOutput = tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR-1L84Ixe6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ4HZqaGAIe",
        "colab_type": "code",
        "outputId": "281212ab-4f48-464f-b2fc-b451bb3a8b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "modelBin = tf.keras.Sequential()\n",
        "modelBin.add(EmbeddingLayer)\n",
        "modelBin.add(BidirectionalLayer)\n",
        "modelBin.add(GlobalMaxPool1DLayer)\n",
        "modelBin.add(DenseLayer)\n",
        "modelBin.add(DropLayer)\n",
        "modelBin.add(DenseLayerOutput)\n",
        "\n",
        "modelBin.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          5120512   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 64)          24832     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 42        \n",
            "=================================================================\n",
            "Total params: 5,146,686\n",
            "Trainable params: 26,174\n",
            "Non-trainable params: 5,120,512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03WxorAGbGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelBin.compile(loss='categorical_crossentropy', #'mean_squared_error'\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoQIZAOpwrwS",
        "colab_type": "text"
      },
      "source": [
        "Trois PISTE  mots frequ entre classe ,  max_features = 6000 ===== > tokenizer = Tokenizer(num_words=max_features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQVdDIiVrJWX",
        "colab_type": "code",
        "outputId": "98f86fc5-f58f-47f5-c1a9-78b5cc79c36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "history = modelBin.fit(training_predictors_tfds, \n",
        "                    training_label_tfds,\n",
        "                    epochs=4,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_tfds, test_label_tfds),\n",
        "                    verbose=1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 81s 3ms/sample - loss: 0.5569 - mse: 0.1888 - mae: 0.3877 - accuracy: 0.7118 - val_loss: 0.4789 - val_mse: 0.1573 - val_mae: 0.3103 - val_accuracy: 0.7668\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 77s 3ms/sample - loss: 0.4415 - mse: 0.1421 - mae: 0.2925 - accuracy: 0.7946 - val_loss: 0.4238 - val_mse: 0.1365 - val_mae: 0.2870 - val_accuracy: 0.8010\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 77s 3ms/sample - loss: 0.3885 - mse: 0.1226 - mae: 0.2531 - accuracy: 0.8288 - val_loss: 0.3781 - val_mse: 0.1193 - val_mae: 0.2578 - val_accuracy: 0.8296\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 78s 3ms/sample - loss: 0.3600 - mse: 0.1122 - mae: 0.2329 - accuracy: 0.8448 - val_loss: 0.3655 - val_mse: 0.1155 - val_mae: 0.2370 - val_accuracy: 0.8366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7L6m8imUZF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8tbz_0eUaI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelBin.compile(loss='categorical_crossentropy', #'mean_squared_error'\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S11DHa9fXKZ5",
        "colab_type": "code",
        "outputId": "9199aceb-0732-4358-fb0f-25147f23661e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "history = modelBin.fit(training_predictors_tfds, \n",
        "                    training_label_tfds,\n",
        "                    epochs=3,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_tfds, test_label_tfds),\n",
        "                    verbose=1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 95s 4ms/sample - loss: 0.2990 - mse: 0.0913 - mae: 0.1873 - accuracy: 0.8734 - val_loss: 0.2945 - val_mse: 0.0913 - val_mae: 0.1751 - val_accuracy: 0.8723\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 92s 4ms/sample - loss: 0.1855 - mse: 0.0533 - mae: 0.1126 - accuracy: 0.9281 - val_loss: 0.2788 - val_mse: 0.0853 - val_mae: 0.1543 - val_accuracy: 0.8838\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 91s 4ms/sample - loss: 0.0998 - mse: 0.0266 - mae: 0.0602 - accuracy: 0.9666 - val_loss: 0.2958 - val_mse: 0.0877 - val_mae: 0.1445 - val_accuracy: 0.8811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFWj2eatGg3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DenseLayerOutput_5 = tf.keras.layers.Dense(5, activation=tf.keras.activations.softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtibcmeZGhbi",
        "colab_type": "code",
        "outputId": "a8a51aeb-16bd-4e65-e0aa-10b19bd03a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "model1 = tf.keras.Sequential()\n",
        "model1.add(EmbeddingLayer)\n",
        "model1.add(BidirectionalLayer)\n",
        "model1.add(GlobalMaxPool1DLayer)\n",
        "model1.add(DenseLayer)\n",
        "model1.add(DropLayer)\n",
        "model1.add(DenseLayerOutput_5)\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          5120512   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 64)          24832     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 105       \n",
            "=================================================================\n",
            "Total params: 5,146,749\n",
            "Trainable params: 5,146,749\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tt-sgMnGj60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r_qQcu3p_wQ",
        "colab_type": "code",
        "outputId": "4607835a-4a93-47d8-cde5-06818a73c5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "history = model1.fit(training_predictors, \n",
        "                    training_label,\n",
        "                    epochs=5,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors, test_label),\n",
        "                    verbose=1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7984 samples, validate on 2016 samples\n",
            "Epoch 1/5\n",
            "7984/7984 [==============================] - 27s 3ms/sample - loss: 1.3373 - mse: 0.1370 - mae: 0.2798 - accuracy: 0.4305 - val_loss: 1.1658 - val_mse: 0.1211 - val_mae: 0.2487 - val_accuracy: 0.5015\n",
            "Epoch 2/5\n",
            "7984/7984 [==============================] - 23s 3ms/sample - loss: 1.0715 - mse: 0.1138 - mae: 0.2342 - accuracy: 0.5410 - val_loss: 1.0087 - val_mse: 0.1078 - val_mae: 0.2254 - val_accuracy: 0.5779\n",
            "Epoch 3/5\n",
            "7984/7984 [==============================] - 23s 3ms/sample - loss: 0.9366 - mse: 0.1028 - mae: 0.2112 - accuracy: 0.5976 - val_loss: 0.9452 - val_mse: 0.1017 - val_mae: 0.2047 - val_accuracy: 0.6066\n",
            "Epoch 4/5\n",
            "7984/7984 [==============================] - 23s 3ms/sample - loss: 0.8429 - mse: 0.0942 - mae: 0.1939 - accuracy: 0.6465 - val_loss: 0.9088 - val_mse: 0.0997 - val_mae: 0.2016 - val_accuracy: 0.6091\n",
            "Epoch 5/5\n",
            "7984/7984 [==============================] - 23s 3ms/sample - loss: 0.7666 - mse: 0.0864 - mae: 0.1789 - accuracy: 0.6837 - val_loss: 0.9015 - val_mse: 0.0984 - val_mae: 0.1912 - val_accuracy: 0.6200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1U6ccvIDL-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}